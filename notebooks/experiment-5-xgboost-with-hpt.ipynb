{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Dagshub credentials for MLflow tracking\n",
    "dagshub_token = os.getenv('DAGSHUB_PAT')\n",
    "if not dagshub_token:\n",
    "    raise EnvironmentError(\"DAGSHUB_PAT environment variable is not set\")\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = dagshub_token\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = dagshub_token\n",
    "\n",
    "dagshub_url = \"https://dagshub.com\"\n",
    "repo_owner = 'im-vishal'\n",
    "repo_name = 'yt-comment-analyzer-plugin'\n",
    "\n",
    "# Set up MLflow tracking URI\n",
    "mlflow.set_tracking_uri(f'{dagshub_url}/{repo_owner}/{repo_name}.mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/9ce98e3d948b4a5996f239d863156660', creation_time=1730739664575, experiment_id='5', last_update_time=1730739664575, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or create an experiment\n",
    "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # reading from s3\n",
    "# df = pd.read_csv('/content/reddit_preprocessing.csv').dropna()\n",
    "# df.shape\n",
    "\n",
    "# reading from local\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 12:24:51,274] A new study created in memory with name: no-name-2b131e31-f4d1-4152-b479-a23091d6be6c\n",
      "[I 2024-11-06 12:25:34,233] Trial 0 finished with value: 0.7194872494204282 and parameters: {'n_estimators': 254, 'learning_rate': 0.06165810076198497, 'max_depth': 3}. Best is trial 0 with value: 0.7194872494204282.\n",
      "[I 2024-11-06 12:26:55,053] Trial 1 finished with value: 0.5997545342970135 and parameters: {'n_estimators': 88, 'learning_rate': 0.0025373123755756894, 'max_depth': 8}. Best is trial 0 with value: 0.7194872494204282.\n",
      "[I 2024-11-06 12:30:29,683] Trial 2 finished with value: 0.6728487658529934 and parameters: {'n_estimators': 178, 'learning_rate': 0.011176143814372437, 'max_depth': 9}. Best is trial 0 with value: 0.7194872494204282.\n",
      "[I 2024-11-06 12:31:26,543] Trial 3 finished with value: 0.6570298649938634 and parameters: {'n_estimators': 105, 'learning_rate': 0.023035503250195148, 'max_depth': 6}. Best is trial 0 with value: 0.7194872494204282.\n",
      "[I 2024-11-06 12:33:45,640] Trial 4 finished with value: 0.6114823401063685 and parameters: {'n_estimators': 187, 'learning_rate': 0.006840991291542833, 'max_depth': 5}. Best is trial 0 with value: 0.7194872494204282.\n",
      "[I 2024-11-06 12:39:13,467] Trial 5 finished with value: 0.6232101459157234 and parameters: {'n_estimators': 208, 'learning_rate': 0.00039478789171818113, 'max_depth': 10}. Best is trial 0 with value: 0.7194872494204282.\n",
      "[I 2024-11-06 12:41:11,598] Trial 6 finished with value: 0.7279421791899632 and parameters: {'n_estimators': 256, 'learning_rate': 0.032652710707411006, 'max_depth': 6}. Best is trial 6 with value: 0.7279421791899632.\n",
      "[I 2024-11-06 12:42:17,602] Trial 7 finished with value: 0.5417973544252012 and parameters: {'n_estimators': 230, 'learning_rate': 0.0005661982282057229, 'max_depth': 4}. Best is trial 6 with value: 0.7279421791899632.\n",
      "[I 2024-11-06 12:43:32,193] Trial 8 finished with value: 0.5330696849856812 and parameters: {'n_estimators': 248, 'learning_rate': 0.00017247183939975006, 'max_depth': 4}. Best is trial 6 with value: 0.7279421791899632.\n",
      "[I 2024-11-06 12:46:09,000] Trial 9 finished with value: 0.585162961952816 and parameters: {'n_estimators': 233, 'learning_rate': 0.00034238723160708576, 'max_depth': 7}. Best is trial 6 with value: 0.7279421791899632.\n",
      "[I 2024-11-06 12:48:11,136] Trial 10 finished with value: 0.800763671075958 and parameters: {'n_estimators': 286, 'learning_rate': 0.0870403366319362, 'max_depth': 7}. Best is trial 10 with value: 0.800763671075958.\n",
      "[I 2024-11-06 12:50:11,963] Trial 11 finished with value: 0.8082640120005454 and parameters: {'n_estimators': 294, 'learning_rate': 0.09937536457827592, 'max_depth': 7}. Best is trial 11 with value: 0.8082640120005454.\n",
      "[I 2024-11-06 12:52:56,207] Trial 12 finished with value: 0.801581890085913 and parameters: {'n_estimators': 299, 'learning_rate': 0.07404288185828595, 'max_depth': 8}. Best is trial 11 with value: 0.8082640120005454.\n",
      "[I 2024-11-06 12:55:22,615] Trial 13 finished with value: 0.813855175235238 and parameters: {'n_estimators': 292, 'learning_rate': 0.09776435488149661, 'max_depth': 8}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 12:57:35,741] Trial 14 finished with value: 0.6309832265102959 and parameters: {'n_estimators': 127, 'learning_rate': 0.0034783736864240494, 'max_depth': 9}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 12:58:21,334] Trial 15 finished with value: 0.6455747988544934 and parameters: {'n_estimators': 50, 'learning_rate': 0.024138215679355545, 'max_depth': 8}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 13:04:15,995] Trial 16 finished with value: 0.6339833628801309 and parameters: {'n_estimators': 279, 'learning_rate': 0.0013986254904866373, 'max_depth': 10}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 13:06:02,148] Trial 17 finished with value: 0.6558025364789308 and parameters: {'n_estimators': 157, 'learning_rate': 0.01196627986784542, 'max_depth': 7}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 13:09:23,957] Trial 18 finished with value: 0.7673530615027956 and parameters: {'n_estimators': 271, 'learning_rate': 0.04016970883566855, 'max_depth': 9}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 13:10:36,790] Trial 19 finished with value: 0.6645302059184508 and parameters: {'n_estimators': 209, 'learning_rate': 0.01575853843856762, 'max_depth': 5}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 13:13:15,945] Trial 20 finished with value: 0.6421655529796809 and parameters: {'n_estimators': 300, 'learning_rate': 0.005510513158448011, 'max_depth': 6}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 13:15:45,941] Trial 21 finished with value: 0.809764080185463 and parameters: {'n_estimators': 300, 'learning_rate': 0.08772042654943175, 'max_depth': 8}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 13:18:18,171] Trial 22 finished with value: 0.7723987453975181 and parameters: {'n_estimators': 270, 'learning_rate': 0.049901545883624075, 'max_depth': 8}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 13:20:21,231] Trial 23 finished with value: 0.8028092186008455 and parameters: {'n_estimators': 296, 'learning_rate': 0.08637574637876994, 'max_depth': 7}. Best is trial 13 with value: 0.813855175235238.\n",
      "[I 2024-11-06 13:22:54,967] Trial 24 finished with value: 0.8145370244102005 and parameters: {'n_estimators': 266, 'learning_rate': 0.09861079220626895, 'max_depth': 9}. Best is trial 24 with value: 0.8145370244102005.\n",
      "[I 2024-11-06 13:25:53,543] Trial 25 finished with value: 0.7513977908086731 and parameters: {'n_estimators': 234, 'learning_rate': 0.035436923920317984, 'max_depth': 9}. Best is trial 24 with value: 0.8145370244102005.\n",
      "[I 2024-11-06 13:30:17,015] Trial 26 finished with value: 0.7378971771444156 and parameters: {'n_estimators': 265, 'learning_rate': 0.022510100464467653, 'max_depth': 10}. Best is trial 24 with value: 0.8145370244102005.\n",
      "[I 2024-11-06 13:32:21,024] Trial 27 finished with value: 0.7560343651984182 and parameters: {'n_estimators': 199, 'learning_rate': 0.051563309526718705, 'max_depth': 8}. Best is trial 24 with value: 0.8145370244102005.\n",
      "[I 2024-11-06 13:35:18,439] Trial 28 finished with value: 0.7650347743079231 and parameters: {'n_estimators': 239, 'learning_rate': 0.04295502606079107, 'max_depth': 9}. Best is trial 24 with value: 0.8145370244102005.\n",
      "[I 2024-11-06 13:37:29,166] Trial 29 finished with value: 0.7762171007773081 and parameters: {'n_estimators': 159, 'learning_rate': 0.0704253340735681, 'max_depth': 10}. Best is trial 24 with value: 0.8145370244102005.\n",
      "2024/11/06 13:40:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/06 13:41:15 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBoost_SMOTE_TFIDF_Trigrams at: https://dagshub.com/im-vishal/yt-comment-analyzer-plugin.mlflow/#/experiments/5/runs/333e8676cb4e4bf6a791614f5442be40.\n",
      "2024/11/06 13:41:15 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/im-vishal/yt-comment-analyzer-plugin.mlflow/#/experiments/5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 266, 'learning_rate': 0.09861079220626895, 'max_depth': 9}\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.09861079220626895,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=266, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
    "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
    "\n",
    "# Step 2: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "ngram_range = (1, 3)  # Trigram setting\n",
    "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "# Step 4: Train-test split before vectorization and resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
    "\n",
    "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Function to log results in MLflow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "\n",
    "# Step 6: Optuna objective function for XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "\n",
    "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
    "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
    "\n",
    "\n",
    "# Step 7: Run Optuna for XGBoost, log the best model only\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_xgboost, n_trials=30)\n",
    "\n",
    "    # Get the best parameters and log only the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
    "\n",
    "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
    "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
    "    print(best_params)\n",
    "    print(best_model)\n",
    "\n",
    "# Run the experiment for XGBoost\n",
    "run_optuna_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
